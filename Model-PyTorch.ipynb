{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA present:  True\n",
      "CUDA Api ver:  1013\n",
      "CUDnn ver: 7603\n",
      "MKL available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA present: \", torch.backends.cuda.is_built())\n",
    "print(\"CUDA Api ver: \", torch.backends.cuda.sys.api_version)\n",
    "print(\"CUDnn ver:\", torch.backends.cudnn.version())\n",
    "print(\"MKL available: \", torch.backends.mkl.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.double # =torch.float64; torch.floate=torch.float32; torch.half=torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 train data file(s) found.\n"
     ]
    }
   ],
   "source": [
    "# Detect the number of train data mini batches. Shuffle them and divide into a train/test parts.\n",
    "\n",
    "fname_pattern = \"./bengaliai-cv19/train_batch_{:03d}.pickle\"\n",
    "train_test_split = 0.7\n",
    "\n",
    "mbatch_no = 0\n",
    "while os.path.exists(fname_pattern.format(mbatch_no)):\n",
    "    mbatch_no = mbatch_no + 1\n",
    "print(\"{} train data file(s) found.\".format(mbatch_no))\n",
    "\n",
    "mbatch_train_no = round(mbatch_no * 0.7)\n",
    "mbatch_test_no = mbatch_no - mbatch_train_no\n",
    "mbatch_idx = np.random.permutation(mbatch_no)\n",
    "mbatch_train_idx = mbatch_idx[:mbatch_train_no]\n",
    "mbatch_test_idx = mbatch_idx[mbatch_train_no:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up some mini-batch for autoencoder:\n",
    "batchno = mbatch_train_idx[0]\n",
    "batch = pickle.load(open(\"./bengaliai-cv19/train_batch_{:03d}\".format(batchno) + \".pickle\", \"rb\"))\n",
    "X_batch = batch['X'][0:64, :, :].astype(np.float16) / 255.\n",
    "Y_batch = batch['Y'][0:64, :].astype(np.float16) / 255. # X = Y, for an autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_batch.reshape((X_batch.shape[0], X_batch.shape[1] * X_batch.shape[2]))).cuda()\n",
    "Y = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDenseNNModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvDenseNNModel, self).__init__()\n",
    "        self.layers = []\n",
    "        self.layers.append([\n",
    "            lambda Inp: Inp.view(-1, 1, 137, 236)\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=1).cuda().half(),\n",
    "            torch.nn.LeakyReLU(0.2).cuda(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1).cuda()\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1).cuda().half(),\n",
    "            torch.nn.LeakyReLU(0.2).cuda(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1).cuda()\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            torch.nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=1).cuda().half(),\n",
    "            torch.nn.LeakyReLU(0.2).cuda(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1).cuda()\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            torch.nn.Conv2d(16, 1, kernel_size=5, stride=1, padding=1).cuda().half(),\n",
    "            torch.nn.LeakyReLU(0.2).cuda(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1).cuda(),\n",
    "            lambda Inp: Inp.view(-1, 112)\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            torch.nn.Linear(112, 137*236).cuda().half(),\n",
    "            torch.nn.LeakyReLU(0.2).cuda()\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            lambda Inp: Inp.view(-1, 137*236)\n",
    "        ])\n",
    "        self.model_modules = torch.nn.ModuleList()\n",
    "        for layer in self.layers:\n",
    "            for sublayer in layer:\n",
    "                if isinstance(sublayer, torch.nn.Module):\n",
    "                    self.model_modules.append(sublayer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            for sublayer in layer:\n",
    "                x = sublayer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.model_modules.parameters()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1: loss=0.88720703125\n",
      "Iteration #2: loss=nan\n",
      "Iteration #3: loss=nan\n",
      "Iteration #4: loss=nan\n",
      "Iteration #5: loss=nan\n",
      "Iteration #6: loss=nan\n",
      "Iteration #7: loss=nan\n",
      "Iteration #8: loss=nan\n",
      "Iteration #9: loss=nan\n",
      "Iteration #10: loss=nan\n"
     ]
    }
   ],
   "source": [
    "model = ConvDenseNNModel()\n",
    "cost_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(iterations):\n",
    "    Y_pred = model(X).cuda()\n",
    "    loss = cost_fn(Y_pred, Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Iteration #{}: loss={}\".format(i + 1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
