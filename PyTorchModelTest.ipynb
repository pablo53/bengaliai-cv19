{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img, ratio):\n",
    "    sc_img = img.astype(np.float32) / 255.\n",
    "    pil_img = PIL.Image.fromarray(sc_img)\n",
    "    w = pil_img.width\n",
    "    h = pil_img.height\n",
    "    new_w = round(w * ratio)\n",
    "    new_h = round(h * ratio)\n",
    "    new_pil_img = pil_img.resize((new_w, new_h), PIL.Image.ANTIALIAS)\n",
    "    return np.array(new_pil_img)\n",
    "\n",
    "def preprocess_imgs(imgs, ratio):\n",
    "    return np.array([ preprocess_img(img, ratio) for img in imgs ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick up some mini-batch for autoencoder:\n",
    "batch = pickle.load(open(\"./bengaliai-cv19/train_batch_001.pickle\", \"rb\"))\n",
    "X_batch = preprocess_imgs(batch['X'][0:64, :, :], 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fed84539850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_batch[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = X_batch.shape[1]\n",
    "width = X_batch.shape[2]\n",
    "\n",
    "X = torch.from_numpy(X_batch.reshape((X_batch.shape[0], height * width))).cuda()\n",
    "Y = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDenseNNModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvDenseNNModel, self).__init__()\n",
    "        self.layers = []\n",
    "        self.layers.append([\n",
    "            torch.nn.Linear(height * width, height * width // 4).cuda(),\n",
    "            torch.nn.Sigmoid().cuda()\n",
    "        ])\n",
    "        self.layers.append([\n",
    "            torch.nn.Linear(height * width // 4, height * width).cuda(),\n",
    "            torch.nn.Sigmoid().cuda()\n",
    "        ])\n",
    "        self.model_modules = torch.nn.ModuleList()\n",
    "        for layer in self.layers:\n",
    "            for sublayer in layer:\n",
    "                if isinstance(sublayer, torch.nn.Module):\n",
    "                    self.model_modules.append(sublayer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            for sublayer in layer:\n",
    "                x = sublayer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.model_modules.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "iterations = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1000: loss=0.19238586723804474\n",
      "Iteration #2000: loss=0.15295089781284332\n",
      "Iteration #3000: loss=0.11639764904975891\n",
      "Iteration #4000: loss=0.08860469609498978\n",
      "Iteration #5000: loss=0.06974484771490097\n",
      "Iteration #6000: loss=0.057327065616846085\n",
      "Iteration #7000: loss=0.049024052917957306\n",
      "Iteration #8000: loss=0.04329027980566025\n",
      "Iteration #9000: loss=0.03918953984975815\n",
      "Iteration #10000: loss=0.03615977615118027\n",
      "Iteration #11000: loss=0.03385636582970619\n",
      "Iteration #12000: loss=0.03206142783164978\n",
      "Iteration #13000: loss=0.030632715672254562\n",
      "Iteration #14000: loss=0.029474519193172455\n",
      "Iteration #15000: loss=0.028520625084638596\n",
      "Iteration #16000: loss=0.027724066749215126\n",
      "Iteration #17000: loss=0.027050789445638657\n",
      "Iteration #18000: loss=0.02647559903562069\n",
      "Iteration #19000: loss=0.02597951330244541\n",
      "Iteration #20000: loss=0.025548020377755165\n",
      "Iteration #21000: loss=0.02516985312104225\n",
      "Iteration #22000: loss=0.02483612857758999\n",
      "Iteration #23000: loss=0.024539805948734283\n",
      "Iteration #24000: loss=0.02427518367767334\n",
      "Iteration #25000: loss=0.024037668481469154\n",
      "Iteration #26000: loss=0.023823466151952744\n",
      "Iteration #27000: loss=0.02362946979701519\n",
      "Iteration #28000: loss=0.02345304749906063\n",
      "Iteration #29000: loss=0.023292047902941704\n",
      "Iteration #30000: loss=0.023144587874412537\n",
      "Iteration #31000: loss=0.023009102791547775\n",
      "Iteration #32000: loss=0.022884266451001167\n",
      "Iteration #33000: loss=0.022768907248973846\n",
      "Iteration #34000: loss=0.022662043571472168\n",
      "Iteration #35000: loss=0.022562801837921143\n",
      "Iteration #36000: loss=0.02247042767703533\n",
      "Iteration #37000: loss=0.022384265437722206\n",
      "Iteration #38000: loss=0.022303754463791847\n",
      "Iteration #39000: loss=0.022228369489312172\n",
      "Iteration #40000: loss=0.02215762995183468\n",
      "Iteration #41000: loss=0.02209113910794258\n",
      "Iteration #42000: loss=0.022028585895895958\n",
      "Iteration #43000: loss=0.021969612687826157\n",
      "Iteration #44000: loss=0.021913941949605942\n",
      "Iteration #45000: loss=0.021861335262656212\n",
      "Iteration #46000: loss=0.021811578422784805\n",
      "Iteration #47000: loss=0.021764418110251427\n",
      "Iteration #48000: loss=0.021719634532928467\n",
      "Iteration #49000: loss=0.021677054464817047\n",
      "Iteration #50000: loss=0.02163654752075672\n",
      "Iteration #51000: loss=0.02159797213971615\n",
      "Iteration #52000: loss=0.021561209112405777\n",
      "Iteration #53000: loss=0.021526146680116653\n",
      "Iteration #54000: loss=0.021492676809430122\n",
      "Iteration #55000: loss=0.02146071195602417\n",
      "Iteration #56000: loss=0.021430162712931633\n",
      "Iteration #57000: loss=0.021400922909379005\n",
      "Iteration #58000: loss=0.021372919902205467\n",
      "Iteration #59000: loss=0.021346082910895348\n",
      "Iteration #60000: loss=0.021320316940546036\n",
      "Iteration #61000: loss=0.02129555493593216\n",
      "Iteration #62000: loss=0.021271726116538048\n",
      "Iteration #63000: loss=0.02124878019094467\n",
      "Iteration #64000: loss=0.0212266743183136\n",
      "Iteration #65000: loss=0.021205388009548187\n",
      "Iteration #66000: loss=0.0211848895996809\n",
      "Iteration #67000: loss=0.0211651511490345\n",
      "Iteration #68000: loss=0.021146129816770554\n",
      "Iteration #69000: loss=0.02112780138850212\n",
      "Iteration #70000: loss=0.02111012116074562\n",
      "Iteration #71000: loss=0.021093053743243217\n",
      "Iteration #72000: loss=0.021076571196317673\n",
      "Iteration #73000: loss=0.021060636267066002\n",
      "Iteration #74000: loss=0.021045217290520668\n",
      "Iteration #75000: loss=0.021030288189649582\n",
      "Iteration #76000: loss=0.021015843376517296\n",
      "Iteration #77000: loss=0.02100185677409172\n",
      "Iteration #78000: loss=0.020988324657082558\n",
      "Iteration #79000: loss=0.02097521349787712\n",
      "Iteration #80000: loss=0.020962515845894814\n",
      "Iteration #81000: loss=0.020950203761458397\n",
      "Iteration #82000: loss=0.020938262343406677\n",
      "Iteration #83000: loss=0.020926661789417267\n",
      "Iteration #84000: loss=0.020915385335683823\n",
      "Iteration #85000: loss=0.020904410630464554\n",
      "Iteration #86000: loss=0.020893720909953117\n",
      "Iteration #87000: loss=0.02088329568505287\n",
      "Iteration #88000: loss=0.02087312377989292\n",
      "Iteration #89000: loss=0.02086319588124752\n",
      "Iteration #90000: loss=0.02085351198911667\n",
      "Iteration #91000: loss=0.02084406092762947\n",
      "Iteration #92000: loss=0.020834840834140778\n",
      "Iteration #93000: loss=0.02082584612071514\n",
      "Iteration #94000: loss=0.02081707864999771\n",
      "Iteration #95000: loss=0.020808527246117592\n",
      "Iteration #96000: loss=0.02080020122230053\n",
      "Iteration #97000: loss=0.020792094990611076\n",
      "Iteration #98000: loss=0.020784208551049232\n",
      "Iteration #99000: loss=0.0207765344530344\n",
      "Iteration #100000: loss=0.020769063383340836\n",
      "Iteration #101000: loss=0.020761782303452492\n",
      "Iteration #102000: loss=0.02075469121336937\n",
      "Iteration #103000: loss=0.020747777074575424\n",
      "Iteration #104000: loss=0.02074103243649006\n",
      "Iteration #105000: loss=0.020734449848532677\n",
      "Iteration #106000: loss=0.020728016272187233\n",
      "Iteration #107000: loss=0.02072172611951828\n",
      "Iteration #108000: loss=0.020715566352009773\n",
      "Iteration #109000: loss=0.020709536969661713\n",
      "Iteration #110000: loss=0.02070363238453865\n",
      "Iteration #111000: loss=0.020697850733995438\n",
      "Iteration #112000: loss=0.020692192018032074\n",
      "Iteration #113000: loss=0.020686650648713112\n",
      "Iteration #114000: loss=0.020681224763393402\n",
      "Iteration #115000: loss=0.020675910636782646\n",
      "Iteration #116000: loss=0.020670704543590546\n",
      "Iteration #117000: loss=0.02066560834646225\n",
      "Iteration #118000: loss=0.020660609006881714\n",
      "Iteration #119000: loss=0.020655713975429535\n",
      "Iteration #120000: loss=0.020650917664170265\n",
      "Iteration #121000: loss=0.020646220073103905\n",
      "Iteration #122000: loss=0.020641611889004707\n",
      "Iteration #123000: loss=0.020637094974517822\n",
      "Iteration #124000: loss=0.020632663741707802\n",
      "Iteration #125000: loss=0.020628321915864944\n",
      "Iteration #126000: loss=0.020624062046408653\n",
      "Iteration #127000: loss=0.020619885995984077\n",
      "Iteration #128000: loss=0.020615795627236366\n",
      "Iteration #129000: loss=0.02061178721487522\n",
      "Iteration #130000: loss=0.020607858896255493\n",
      "Iteration #131000: loss=0.02060401625931263\n",
      "Iteration #132000: loss=0.020600251853466034\n",
      "Iteration #133000: loss=0.020596569404006004\n",
      "Iteration #134000: loss=0.020592963322997093\n",
      "Iteration #135000: loss=0.02058943547308445\n",
      "Iteration #136000: loss=0.020585976541042328\n",
      "Iteration #137000: loss=0.020582586526870728\n",
      "Iteration #138000: loss=0.02057926543056965\n",
      "Iteration #139000: loss=0.020576003938913345\n",
      "Iteration #140000: loss=0.020572807639837265\n",
      "Iteration #141000: loss=0.020569661632180214\n",
      "Iteration #142000: loss=0.02056657336652279\n",
      "Iteration #143000: loss=0.020563529804348946\n",
      "Iteration #144000: loss=0.020560534670948982\n",
      "Iteration #145000: loss=0.020557580515742302\n",
      "Iteration #146000: loss=0.020554672926664352\n",
      "Iteration #147000: loss=0.020551806315779686\n",
      "Iteration #148000: loss=0.020548980683088303\n",
      "Iteration #149000: loss=0.020546192303299904\n",
      "Iteration #150000: loss=0.02054344117641449\n",
      "Iteration #151000: loss=0.02054072916507721\n",
      "Iteration #152000: loss=0.020538050681352615\n",
      "Iteration #153000: loss=0.020535413175821304\n",
      "Iteration #154000: loss=0.020532803609967232\n",
      "Iteration #155000: loss=0.020530235022306442\n",
      "Iteration #156000: loss=0.02052769623696804\n",
      "Iteration #157000: loss=0.020525187253952026\n",
      "Iteration #158000: loss=0.02052270993590355\n",
      "Iteration #159000: loss=0.02052026242017746\n",
      "Iteration #160000: loss=0.020517844706773758\n",
      "Iteration #161000: loss=0.020515456795692444\n",
      "Iteration #162000: loss=0.020513098686933517\n",
      "Iteration #163000: loss=0.02051076851785183\n",
      "Iteration #164000: loss=0.02050846442580223\n",
      "Iteration #165000: loss=0.020506184548139572\n",
      "Iteration #166000: loss=0.020503932610154152\n",
      "Iteration #167000: loss=0.02050170488655567\n",
      "Iteration #168000: loss=0.02049950510263443\n",
      "Iteration #169000: loss=0.020497329533100128\n",
      "Iteration #170000: loss=0.020495178177952766\n",
      "Iteration #171000: loss=0.020493054762482643\n",
      "Iteration #172000: loss=0.02049095742404461\n",
      "Iteration #173000: loss=0.020488884299993515\n",
      "Iteration #174000: loss=0.02048683725297451\n",
      "Iteration #175000: loss=0.020484812557697296\n",
      "Iteration #176000: loss=0.02048281580209732\n",
      "Iteration #177000: loss=0.020480839535593987\n",
      "Iteration #178000: loss=0.02047888934612274\n",
      "Iteration #179000: loss=0.020476963371038437\n",
      "Iteration #180000: loss=0.02047506347298622\n",
      "Iteration #181000: loss=0.020473185926675797\n",
      "Iteration #182000: loss=0.02047133445739746\n",
      "Iteration #183000: loss=0.020469507202506065\n",
      "Iteration #184000: loss=0.02046770229935646\n",
      "Iteration #185000: loss=0.020465921610593796\n",
      "Iteration #186000: loss=0.02046416513621807\n",
      "Iteration #187000: loss=0.020462431013584137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #188000: loss=0.020460722967982292\n",
      "Iteration #189000: loss=0.02045903354883194\n",
      "Iteration #190000: loss=0.020457368344068527\n",
      "Iteration #191000: loss=0.020455723628401756\n",
      "Iteration #192000: loss=0.020454104989767075\n",
      "Iteration #193000: loss=0.020452501252293587\n",
      "Iteration #194000: loss=0.02045092172920704\n",
      "Iteration #195000: loss=0.020449362695217133\n",
      "Iteration #196000: loss=0.02044782228767872\n",
      "Iteration #197000: loss=0.020446302369236946\n",
      "Iteration #198000: loss=0.020444802939891815\n",
      "Iteration #199000: loss=0.020443322136998177\n",
      "Iteration #200000: loss=0.02044186182320118\n",
      "Iteration #201000: loss=0.020440421998500824\n",
      "Iteration #202000: loss=0.02043899893760681\n",
      "Iteration #203000: loss=0.02043760009109974\n",
      "Iteration #204000: loss=0.020436221733689308\n",
      "Iteration #205000: loss=0.020434867590665817\n",
      "Iteration #206000: loss=0.02043353021144867\n",
      "Iteration #207000: loss=0.02043221704661846\n",
      "Iteration #208000: loss=0.020430926233530045\n",
      "Iteration #209000: loss=0.02042965777218342\n",
      "Iteration #210000: loss=0.020428407937288284\n",
      "Iteration #211000: loss=0.02042718231678009\n",
      "Iteration #212000: loss=0.02042597532272339\n",
      "Iteration #213000: loss=0.02042478881776333\n",
      "Iteration #214000: loss=0.02042362093925476\n",
      "Iteration #215000: loss=0.020422471687197685\n",
      "Iteration #216000: loss=0.020421341061592102\n",
      "Iteration #217000: loss=0.02042023092508316\n",
      "Iteration #218000: loss=0.020419135689735413\n",
      "Iteration #219000: loss=0.02041805163025856\n",
      "Iteration #220000: loss=0.02041698805987835\n",
      "Iteration #221000: loss=0.020415933802723885\n",
      "Iteration #222000: loss=0.020414892584085464\n",
      "Iteration #223000: loss=0.02041386440396309\n",
      "Iteration #224000: loss=0.02041284181177616\n",
      "Iteration #225000: loss=0.020411832258105278\n",
      "Iteration #226000: loss=0.020410830155014992\n",
      "Iteration #227000: loss=0.0204098392277956\n",
      "Iteration #228000: loss=0.020408855751156807\n",
      "Iteration #229000: loss=0.02040788345038891\n",
      "Iteration #230000: loss=0.020406916737556458\n",
      "Iteration #231000: loss=0.020405961200594902\n",
      "Iteration #232000: loss=0.020405011251568794\n",
      "Iteration #233000: loss=0.020404068753123283\n",
      "Iteration #234000: loss=0.020403137430548668\n",
      "Iteration #235000: loss=0.0204022116959095\n",
      "Iteration #236000: loss=0.02040129341185093\n",
      "Iteration #237000: loss=0.020400382578372955\n",
      "Iteration #238000: loss=0.020399481058120728\n",
      "Iteration #239000: loss=0.020398586988449097\n",
      "Iteration #240000: loss=0.020397700369358063\n",
      "Iteration #241000: loss=0.020396823063492775\n",
      "Iteration #242000: loss=0.020395953208208084\n",
      "Iteration #243000: loss=0.02039509080350399\n",
      "Iteration #244000: loss=0.020394235849380493\n",
      "Iteration #245000: loss=0.020393388345837593\n",
      "Iteration #246000: loss=0.02039255015552044\n",
      "Iteration #247000: loss=0.020391719415783882\n",
      "Iteration #248000: loss=0.020390892401337624\n",
      "Iteration #249000: loss=0.02039007842540741\n",
      "Iteration #250000: loss=0.020389271900057793\n",
      "Iteration #251000: loss=0.020388469099998474\n",
      "Iteration #252000: loss=0.0203876756131649\n",
      "Iteration #253000: loss=0.020386889576911926\n",
      "Iteration #254000: loss=0.020386110991239548\n",
      "Iteration #255000: loss=0.020385337993502617\n",
      "Iteration #256000: loss=0.020384574308991432\n",
      "Iteration #257000: loss=0.020383816212415695\n",
      "Iteration #258000: loss=0.020383063703775406\n",
      "Iteration #259000: loss=0.020382320508360863\n",
      "Iteration #260000: loss=0.020381581038236618\n",
      "Iteration #261000: loss=0.02038084715604782\n",
      "Iteration #262000: loss=0.02038012258708477\n",
      "Iteration #263000: loss=0.020379403606057167\n",
      "Iteration #264000: loss=0.020378686487674713\n",
      "Iteration #265000: loss=0.020377976819872856\n",
      "Iteration #266000: loss=0.020377274602651596\n",
      "Iteration #267000: loss=0.020376576110720634\n",
      "Iteration #268000: loss=0.02037588134407997\n",
      "Iteration #269000: loss=0.020375195890665054\n",
      "Iteration #270000: loss=0.020374512299895287\n",
      "Iteration #271000: loss=0.020373834297060966\n",
      "Iteration #272000: loss=0.020373163744807243\n",
      "Iteration #273000: loss=0.02037249505519867\n",
      "Iteration #274000: loss=0.020371831953525543\n",
      "Iteration #275000: loss=0.020371174439787865\n",
      "Iteration #276000: loss=0.020370522513985634\n",
      "Iteration #277000: loss=0.02036987617611885\n",
      "Iteration #278000: loss=0.020369233563542366\n",
      "Iteration #279000: loss=0.02036859653890133\n",
      "Iteration #280000: loss=0.02036796137690544\n",
      "Iteration #281000: loss=0.0203673355281353\n",
      "Iteration #282000: loss=0.020366709679365158\n",
      "Iteration #283000: loss=0.020366091281175613\n",
      "Iteration #284000: loss=0.020365474745631218\n",
      "Iteration #285000: loss=0.02036486566066742\n",
      "Iteration #286000: loss=0.02036426216363907\n",
      "Iteration #287000: loss=0.020363660529255867\n",
      "Iteration #288000: loss=0.020363062620162964\n",
      "Iteration #289000: loss=0.02036247029900551\n",
      "Iteration #290000: loss=0.0203618835657835\n",
      "Iteration #291000: loss=0.02036130242049694\n",
      "Iteration #292000: loss=0.02036072313785553\n",
      "Iteration #293000: loss=0.020360153168439865\n",
      "Iteration #294000: loss=0.02035958506166935\n",
      "Iteration #295000: loss=0.020359020680189133\n",
      "Iteration #296000: loss=0.020358465611934662\n",
      "Iteration #297000: loss=0.02035791426897049\n",
      "Iteration #298000: loss=0.020357366651296616\n",
      "Iteration #299000: loss=0.02035682462155819\n",
      "Iteration #300000: loss=0.02035629190504551\n",
      "Iteration #301000: loss=0.02035575918853283\n",
      "Iteration #302000: loss=0.020355235785245895\n",
      "Iteration #303000: loss=0.02035471238195896\n",
      "Iteration #304000: loss=0.020354200154542923\n",
      "Iteration #305000: loss=0.020353691652417183\n",
      "Iteration #306000: loss=0.020353185012936592\n",
      "Iteration #307000: loss=0.020352687686681747\n",
      "Iteration #308000: loss=0.0203521940857172\n",
      "Iteration #309000: loss=0.020351707935333252\n",
      "Iteration #310000: loss=0.020351221784949303\n",
      "Iteration #311000: loss=0.02035074681043625\n",
      "Iteration #312000: loss=0.020350271835923195\n",
      "Iteration #313000: loss=0.020349806174635887\n",
      "Iteration #314000: loss=0.02034934237599373\n",
      "Iteration #315000: loss=0.02034888230264187\n",
      "Iteration #316000: loss=0.020348424091935158\n",
      "Iteration #317000: loss=0.020347973331809044\n",
      "Iteration #318000: loss=0.02034752443432808\n",
      "Iteration #319000: loss=0.020347079262137413\n",
      "Iteration #320000: loss=0.020346637815237045\n",
      "Iteration #321000: loss=0.020346201956272125\n",
      "Iteration #322000: loss=0.020345766097307205\n",
      "Iteration #323000: loss=0.020345333963632584\n",
      "Iteration #324000: loss=0.02034490555524826\n",
      "Iteration #325000: loss=0.020344479009509087\n",
      "Iteration #326000: loss=0.02034405618906021\n",
      "Iteration #327000: loss=0.020343635231256485\n",
      "Iteration #328000: loss=0.02034321241080761\n",
      "Iteration #329000: loss=0.02034279704093933\n",
      "Iteration #330000: loss=0.020342381671071053\n",
      "Iteration #331000: loss=0.020341971889138222\n",
      "Iteration #332000: loss=0.02034156210720539\n",
      "Iteration #333000: loss=0.02034115605056286\n",
      "Iteration #334000: loss=0.020340751856565475\n",
      "Iteration #335000: loss=0.02034035138785839\n",
      "Iteration #336000: loss=0.020339952781796455\n",
      "Iteration #337000: loss=0.02033955417573452\n",
      "Iteration #338000: loss=0.020339159294962883\n",
      "Iteration #339000: loss=0.020338768139481544\n",
      "Iteration #340000: loss=0.020338376984000206\n",
      "Iteration #341000: loss=0.020337989553809166\n",
      "Iteration #342000: loss=0.020337602123618126\n",
      "Iteration #343000: loss=0.020337220281362534\n",
      "Iteration #344000: loss=0.02033684030175209\n",
      "Iteration #345000: loss=0.020336458459496498\n",
      "Iteration #346000: loss=0.020336084067821503\n",
      "Iteration #347000: loss=0.020335709676146507\n",
      "Iteration #348000: loss=0.020335335284471512\n",
      "Iteration #349000: loss=0.020334966480731964\n",
      "Iteration #350000: loss=0.020334595814347267\n",
      "Iteration #351000: loss=0.020334230735898018\n",
      "Iteration #352000: loss=0.020333871245384216\n",
      "Iteration #353000: loss=0.020333509892225266\n",
      "Iteration #354000: loss=0.020333148539066315\n",
      "Iteration #355000: loss=0.02033279277384281\n",
      "Iteration #356000: loss=0.020332438871264458\n",
      "Iteration #357000: loss=0.020332083106040955\n",
      "Iteration #358000: loss=0.02033173106610775\n",
      "Iteration #359000: loss=0.020331384614109993\n",
      "Iteration #360000: loss=0.020331036299467087\n",
      "Iteration #361000: loss=0.02033069357275963\n",
      "Iteration #362000: loss=0.02033034898340702\n",
      "Iteration #363000: loss=0.020330006256699562\n",
      "Iteration #364000: loss=0.020329667255282402\n",
      "Iteration #365000: loss=0.02032933197915554\n",
      "Iteration #366000: loss=0.02032899484038353\n",
      "Iteration #367000: loss=0.020328663289546967\n",
      "Iteration #368000: loss=0.020328329876065254\n",
      "Iteration #369000: loss=0.02032800205051899\n",
      "Iteration #370000: loss=0.020327674224972725\n",
      "Iteration #371000: loss=0.02032734826207161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #372000: loss=0.020327024161815643\n",
      "Iteration #373000: loss=0.020326700061559677\n",
      "Iteration #374000: loss=0.02032637968659401\n",
      "Iteration #375000: loss=0.02032606117427349\n",
      "Iteration #376000: loss=0.020325742661952972\n",
      "Iteration #377000: loss=0.020325427874922752\n",
      "Iteration #378000: loss=0.02032511495053768\n",
      "Iteration #379000: loss=0.02032480575144291\n",
      "Iteration #380000: loss=0.020324496552348137\n",
      "Iteration #381000: loss=0.020324189215898514\n",
      "Iteration #382000: loss=0.02032388560473919\n",
      "Iteration #383000: loss=0.020323580130934715\n",
      "Iteration #384000: loss=0.02032328024506569\n",
      "Iteration #385000: loss=0.020322982221841812\n",
      "Iteration #386000: loss=0.020322684198617935\n",
      "Iteration #387000: loss=0.020322389900684357\n",
      "Iteration #388000: loss=0.020322097465395927\n",
      "Iteration #389000: loss=0.020321806892752647\n",
      "Iteration #390000: loss=0.020321520045399666\n",
      "Iteration #391000: loss=0.020321231335401535\n",
      "Iteration #392000: loss=0.020320946350693703\n",
      "Iteration #393000: loss=0.02032066509127617\n",
      "Iteration #394000: loss=0.020320385694503784\n",
      "Iteration #395000: loss=0.0203201062977314\n",
      "Iteration #396000: loss=0.020319830626249313\n",
      "Iteration #397000: loss=0.020319556817412376\n",
      "Iteration #398000: loss=0.02031928487122059\n",
      "Iteration #399000: loss=0.0203190166503191\n",
      "Iteration #400000: loss=0.02031874656677246\n",
      "Iteration #401000: loss=0.02031848207116127\n",
      "Iteration #402000: loss=0.02031821757555008\n",
      "Iteration #403000: loss=0.020317956805229187\n",
      "Iteration #404000: loss=0.020317696034908295\n",
      "Iteration #405000: loss=0.02031743712723255\n",
      "Iteration #406000: loss=0.020317181944847107\n",
      "Iteration #407000: loss=0.02031692862510681\n",
      "Iteration #408000: loss=0.020316673442721367\n",
      "Iteration #409000: loss=0.02031642571091652\n",
      "Iteration #410000: loss=0.020316174253821373\n",
      "Iteration #411000: loss=0.020315924659371376\n",
      "Iteration #412000: loss=0.020315678790211678\n",
      "Iteration #413000: loss=0.02031543478369713\n",
      "Iteration #414000: loss=0.02031519077718258\n",
      "Iteration #415000: loss=0.02031494677066803\n",
      "Iteration #416000: loss=0.020314708352088928\n",
      "Iteration #417000: loss=0.020314468070864677\n",
      "Iteration #418000: loss=0.020314229652285576\n",
      "Iteration #419000: loss=0.020313991233706474\n",
      "Iteration #420000: loss=0.02031375654041767\n",
      "Iteration #421000: loss=0.02031351812183857\n",
      "Iteration #422000: loss=0.020313287153840065\n",
      "Iteration #423000: loss=0.02031305618584156\n",
      "Iteration #424000: loss=0.020312821492552757\n",
      "Iteration #425000: loss=0.020312590524554253\n",
      "Iteration #426000: loss=0.020312363281846046\n",
      "Iteration #427000: loss=0.02031213417649269\n",
      "Iteration #428000: loss=0.020311906933784485\n",
      "Iteration #429000: loss=0.020311681553721428\n",
      "Iteration #430000: loss=0.02031145617365837\n",
      "Iteration #431000: loss=0.020311232656240463\n",
      "Iteration #432000: loss=0.020311009138822556\n",
      "Iteration #433000: loss=0.020310787484049797\n",
      "Iteration #434000: loss=0.020310567691922188\n",
      "Iteration #435000: loss=0.02031034789979458\n",
      "Iteration #436000: loss=0.02031012997031212\n",
      "Iteration #437000: loss=0.02030991017818451\n",
      "Iteration #438000: loss=0.020309695973992348\n",
      "Iteration #439000: loss=0.020309478044509888\n",
      "Iteration #440000: loss=0.020309265702962875\n",
      "Iteration #441000: loss=0.020309051498770714\n",
      "Iteration #442000: loss=0.0203088391572237\n",
      "Iteration #443000: loss=0.02030862681567669\n",
      "Iteration #444000: loss=0.020308418199419975\n",
      "Iteration #445000: loss=0.02030820958316326\n",
      "Iteration #446000: loss=0.020308000966906548\n",
      "Iteration #447000: loss=0.020307792350649834\n",
      "Iteration #448000: loss=0.02030758559703827\n",
      "Iteration #449000: loss=0.020307378843426704\n",
      "Iteration #450000: loss=0.02030717395246029\n",
      "Iteration #451000: loss=0.020306969061493874\n",
      "Iteration #452000: loss=0.020306769758462906\n",
      "Iteration #453000: loss=0.02030656486749649\n",
      "Iteration #454000: loss=0.020306365564465523\n",
      "Iteration #455000: loss=0.020306166261434555\n",
      "Iteration #456000: loss=0.020305966958403587\n",
      "Iteration #457000: loss=0.02030576951801777\n",
      "Iteration #458000: loss=0.0203055739402771\n",
      "Iteration #459000: loss=0.02030537836253643\n",
      "Iteration #460000: loss=0.02030518278479576\n",
      "Iteration #461000: loss=0.02030498906970024\n",
      "Iteration #462000: loss=0.02030479535460472\n",
      "Iteration #463000: loss=0.0203046053647995\n",
      "Iteration #464000: loss=0.02030441351234913\n",
      "Iteration #465000: loss=0.020304225385189056\n",
      "Iteration #466000: loss=0.020304035395383835\n",
      "Iteration #467000: loss=0.020303845405578613\n",
      "Iteration #468000: loss=0.02030366100370884\n",
      "Iteration #469000: loss=0.020303474739193916\n",
      "Iteration #470000: loss=0.020303290337324142\n",
      "Iteration #471000: loss=0.02030310593545437\n",
      "Iteration #472000: loss=0.020302923396229744\n",
      "Iteration #473000: loss=0.02030274271965027\n",
      "Iteration #474000: loss=0.020302562043070793\n",
      "Iteration #475000: loss=0.02030237950384617\n",
      "Iteration #476000: loss=0.020302200689911842\n",
      "Iteration #477000: loss=0.020302025601267815\n",
      "Iteration #478000: loss=0.02030184678733349\n",
      "Iteration #479000: loss=0.02030166983604431\n",
      "Iteration #480000: loss=0.020301496610045433\n",
      "Iteration #481000: loss=0.020301323384046555\n",
      "Iteration #482000: loss=0.020301146432757378\n",
      "Iteration #483000: loss=0.02030097506940365\n",
      "Iteration #484000: loss=0.02030080370604992\n",
      "Iteration #485000: loss=0.02030063234269619\n",
      "Iteration #486000: loss=0.02030046284198761\n",
      "Iteration #487000: loss=0.02030028961598873\n",
      "Iteration #488000: loss=0.0203001219779253\n",
      "Iteration #489000: loss=0.02029995247721672\n",
      "Iteration #490000: loss=0.020299788564443588\n",
      "Iteration #491000: loss=0.020299620926380157\n",
      "Iteration #492000: loss=0.020299455150961876\n",
      "Iteration #493000: loss=0.020299293100833893\n",
      "Iteration #494000: loss=0.02029912732541561\n",
      "Iteration #495000: loss=0.02029896154999733\n",
      "Iteration #496000: loss=0.020298801362514496\n",
      "Iteration #497000: loss=0.020298641175031662\n",
      "Iteration #498000: loss=0.02029847912490368\n",
      "Iteration #499000: loss=0.020298318937420845\n",
      "Iteration #500000: loss=0.02029815874993801\n",
      "Iteration #501000: loss=0.020298002287745476\n",
      "Iteration #502000: loss=0.020297842100262642\n",
      "Iteration #503000: loss=0.020297685638070107\n",
      "Iteration #504000: loss=0.02029752917587757\n",
      "Iteration #505000: loss=0.020297374576330185\n",
      "Iteration #506000: loss=0.02029721811413765\n",
      "Iteration #507000: loss=0.020297067239880562\n",
      "Iteration #508000: loss=0.020296912640333176\n",
      "Iteration #509000: loss=0.02029675990343094\n",
      "Iteration #510000: loss=0.020296610891819\n",
      "Iteration #511000: loss=0.020296460017561913\n",
      "Iteration #512000: loss=0.020296311005949974\n",
      "Iteration #513000: loss=0.020296158269047737\n",
      "Iteration #514000: loss=0.020296012982726097\n",
      "Iteration #515000: loss=0.020295867696404457\n",
      "Iteration #516000: loss=0.020295720547437668\n",
      "Iteration #517000: loss=0.020295575261116028\n",
      "Iteration #518000: loss=0.020295431837439537\n",
      "Iteration #519000: loss=0.020295288413763046\n",
      "Iteration #520000: loss=0.020295144990086555\n",
      "Iteration #521000: loss=0.020295005291700363\n",
      "Iteration #522000: loss=0.020294861868023872\n",
      "Iteration #523000: loss=0.02029472589492798\n",
      "Iteration #524000: loss=0.020294584333896637\n",
      "Iteration #525000: loss=0.020294448360800743\n",
      "Iteration #526000: loss=0.02029431238770485\n",
      "Iteration #527000: loss=0.020294176414608955\n",
      "Iteration #528000: loss=0.02029404602944851\n",
      "Iteration #529000: loss=0.020293910056352615\n",
      "Iteration #530000: loss=0.02029377780854702\n",
      "Iteration #531000: loss=0.020293647423386574\n",
      "Iteration #532000: loss=0.020293518900871277\n",
      "Iteration #533000: loss=0.02029339410364628\n",
      "Iteration #534000: loss=0.02029326744377613\n",
      "Iteration #535000: loss=0.020293142646551132\n",
      "Iteration #536000: loss=0.020293019711971283\n",
      "Iteration #537000: loss=0.020292900502681732\n",
      "Iteration #538000: loss=0.02029278129339218\n",
      "Iteration #539000: loss=0.02029266022145748\n",
      "Iteration #540000: loss=0.02029254660010338\n",
      "Iteration #541000: loss=0.020292427390813828\n",
      "Iteration #542000: loss=0.020292315632104874\n",
      "Iteration #543000: loss=0.02029220201075077\n",
      "Iteration #544000: loss=0.020292092114686966\n",
      "Iteration #545000: loss=0.02029198408126831\n",
      "Iteration #546000: loss=0.020291876047849655\n",
      "Iteration #547000: loss=0.02029176987707615\n",
      "Iteration #548000: loss=0.020291665568947792\n",
      "Iteration #549000: loss=0.020291561260819435\n",
      "Iteration #550000: loss=0.020291460677981377\n",
      "Iteration #551000: loss=0.020291361957788467\n",
      "Iteration #552000: loss=0.020291263237595558\n",
      "Iteration #553000: loss=0.020291168242692947\n",
      "Iteration #554000: loss=0.020291071385145187\n",
      "Iteration #555000: loss=0.020290976390242577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #556000: loss=0.020290885120630264\n",
      "Iteration #557000: loss=0.020290793851017952\n",
      "Iteration #558000: loss=0.020290706306695938\n",
      "Iteration #559000: loss=0.020290616899728775\n",
      "Iteration #560000: loss=0.02029053121805191\n",
      "Iteration #561000: loss=0.020290445536375046\n",
      "Iteration #562000: loss=0.02029036357998848\n",
      "Iteration #563000: loss=0.020290281623601913\n",
      "Iteration #564000: loss=0.020290197804570198\n",
      "Iteration #565000: loss=0.02029011957347393\n",
      "Iteration #566000: loss=0.020290039479732513\n",
      "Iteration #567000: loss=0.020289963111281395\n",
      "Iteration #568000: loss=0.020289884880185127\n",
      "Iteration #569000: loss=0.02028980851173401\n",
      "Iteration #570000: loss=0.02028973586857319\n",
      "Iteration #571000: loss=0.02028966136276722\n",
      "Iteration #572000: loss=0.0202895887196064\n",
      "Iteration #573000: loss=0.02028951607644558\n",
      "Iteration #574000: loss=0.02028944529592991\n",
      "Iteration #575000: loss=0.020289376378059387\n",
      "Iteration #576000: loss=0.020289305597543716\n",
      "Iteration #577000: loss=0.020289234817028046\n",
      "Iteration #578000: loss=0.020289167761802673\n",
      "Iteration #579000: loss=0.0202891007065773\n",
      "Iteration #580000: loss=0.02028903365135193\n",
      "Iteration #581000: loss=0.020288966596126556\n",
      "Iteration #582000: loss=0.020288897678256035\n",
      "Iteration #583000: loss=0.020288832485675812\n",
      "Iteration #584000: loss=0.02028876729309559\n",
      "Iteration #585000: loss=0.020288700237870216\n",
      "Iteration #586000: loss=0.020288636907935143\n",
      "Iteration #587000: loss=0.02028857171535492\n",
      "Iteration #588000: loss=0.020288506522774696\n",
      "Iteration #589000: loss=0.020288441330194473\n",
      "Iteration #590000: loss=0.02028837613761425\n",
      "Iteration #591000: loss=0.020288312807679176\n",
      "Iteration #592000: loss=0.02028825134038925\n",
      "Iteration #593000: loss=0.02028818614780903\n",
      "Iteration #594000: loss=0.020288122817873955\n",
      "Iteration #595000: loss=0.02028805948793888\n",
      "Iteration #596000: loss=0.020287994295358658\n",
      "Iteration #597000: loss=0.020287932828068733\n",
      "Iteration #598000: loss=0.02028786949813366\n",
      "Iteration #599000: loss=0.020287808030843735\n",
      "Iteration #600000: loss=0.02028774470090866\n",
      "Iteration #601000: loss=0.020287683233618736\n",
      "Iteration #602000: loss=0.020287619903683662\n",
      "Iteration #603000: loss=0.02028755657374859\n",
      "Iteration #604000: loss=0.020287495106458664\n",
      "Iteration #605000: loss=0.02028743363916874\n",
      "Iteration #606000: loss=0.020287372171878815\n",
      "Iteration #607000: loss=0.02028731070458889\n",
      "Iteration #608000: loss=0.020287249237298965\n",
      "Iteration #609000: loss=0.02028718590736389\n",
      "Iteration #610000: loss=0.020287124440073967\n",
      "Iteration #611000: loss=0.020287062972784042\n",
      "Iteration #612000: loss=0.020287003368139267\n",
      "Iteration #613000: loss=0.020286941900849342\n",
      "Iteration #614000: loss=0.020286880433559418\n",
      "Iteration #615000: loss=0.020286820828914642\n",
      "Iteration #616000: loss=0.020286759361624718\n",
      "Iteration #617000: loss=0.020286697894334793\n",
      "Iteration #618000: loss=0.020286638289690018\n",
      "Iteration #619000: loss=0.020286576822400093\n",
      "Iteration #620000: loss=0.020286519080400467\n",
      "Iteration #621000: loss=0.020286457613110542\n",
      "Iteration #622000: loss=0.020286398008465767\n",
      "Iteration #623000: loss=0.02028633840382099\n",
      "Iteration #624000: loss=0.020286276936531067\n",
      "Iteration #625000: loss=0.020286215469241142\n",
      "Iteration #626000: loss=0.020286157727241516\n",
      "Iteration #627000: loss=0.02028609812259674\n",
      "Iteration #628000: loss=0.020286038517951965\n",
      "Iteration #629000: loss=0.02028597891330719\n",
      "Iteration #630000: loss=0.020285921171307564\n",
      "Iteration #631000: loss=0.02028585970401764\n",
      "Iteration #632000: loss=0.020285803824663162\n",
      "Iteration #633000: loss=0.020285742357373238\n",
      "Iteration #634000: loss=0.020285682752728462\n",
      "Iteration #635000: loss=0.020285625010728836\n",
      "Iteration #636000: loss=0.02028556354343891\n",
      "Iteration #637000: loss=0.020285505801439285\n",
      "Iteration #638000: loss=0.02028544619679451\n",
      "Iteration #639000: loss=0.020285388454794884\n",
      "Iteration #640000: loss=0.020285330712795258\n",
      "Iteration #641000: loss=0.02028527297079563\n",
      "Iteration #642000: loss=0.020285211503505707\n",
      "Iteration #643000: loss=0.02028515562415123\n",
      "Iteration #644000: loss=0.020285096019506454\n",
      "Iteration #645000: loss=0.02028503827750683\n",
      "Iteration #646000: loss=0.02028498239815235\n",
      "Iteration #647000: loss=0.020284922793507576\n",
      "Iteration #648000: loss=0.0202848631888628\n",
      "Iteration #649000: loss=0.020284807309508324\n",
      "Iteration #650000: loss=0.020284751430153847\n",
      "Iteration #651000: loss=0.02028469182550907\n",
      "Iteration #652000: loss=0.020284635946154594\n",
      "Iteration #653000: loss=0.02028457634150982\n",
      "Iteration #654000: loss=0.020284520462155342\n",
      "Iteration #655000: loss=0.020284464582800865\n",
      "Iteration #656000: loss=0.02028440497815609\n",
      "Iteration #657000: loss=0.020284349098801613\n",
      "Iteration #658000: loss=0.020284293219447136\n",
      "Iteration #659000: loss=0.02028423361480236\n",
      "Iteration #660000: loss=0.020284177735447884\n",
      "Iteration #661000: loss=0.020284119993448257\n",
      "Iteration #662000: loss=0.02028406411409378\n",
      "Iteration #663000: loss=0.020284010097384453\n",
      "Iteration #664000: loss=0.020283950492739677\n",
      "Iteration #665000: loss=0.0202838946133852\n",
      "Iteration #666000: loss=0.020283840596675873\n",
      "Iteration #667000: loss=0.020283784717321396\n",
      "Iteration #668000: loss=0.02028372697532177\n",
      "Iteration #669000: loss=0.020283672958612442\n",
      "Iteration #670000: loss=0.020283617079257965\n",
      "Iteration #671000: loss=0.02028355933725834\n",
      "Iteration #672000: loss=0.020283503457903862\n",
      "Iteration #673000: loss=0.020283449441194534\n",
      "Iteration #674000: loss=0.020283391699194908\n",
      "Iteration #675000: loss=0.02028333768248558\n",
      "Iteration #676000: loss=0.020283283665776253\n",
      "Iteration #677000: loss=0.020283227786421776\n",
      "Iteration #678000: loss=0.020283173769712448\n",
      "Iteration #679000: loss=0.02028311789035797\n",
      "Iteration #680000: loss=0.020283062011003494\n",
      "Iteration #681000: loss=0.020283007994294167\n",
      "Iteration #682000: loss=0.02028295397758484\n",
      "Iteration #683000: loss=0.02028289996087551\n",
      "Iteration #684000: loss=0.020282844081521034\n",
      "Iteration #685000: loss=0.020282788202166557\n",
      "Iteration #686000: loss=0.02028273418545723\n",
      "Iteration #687000: loss=0.02028268203139305\n",
      "Iteration #688000: loss=0.020282628014683723\n",
      "Iteration #689000: loss=0.020282573997974396\n",
      "Iteration #690000: loss=0.020282521843910217\n",
      "Iteration #691000: loss=0.02028246410191059\n",
      "Iteration #692000: loss=0.020282411947846413\n",
      "Iteration #693000: loss=0.020282357931137085\n",
      "Iteration #694000: loss=0.020282303914427757\n",
      "Iteration #695000: loss=0.02028225176036358\n",
      "Iteration #696000: loss=0.02028219774365425\n",
      "Iteration #697000: loss=0.020282141864299774\n",
      "Iteration #698000: loss=0.020282089710235596\n",
      "Iteration #699000: loss=0.020282037556171417\n",
      "Iteration #700000: loss=0.02028198353946209\n",
      "Iteration #701000: loss=0.02028193138539791\n",
      "Iteration #702000: loss=0.020281877368688583\n",
      "Iteration #703000: loss=0.020281825214624405\n",
      "Iteration #704000: loss=0.020281773060560226\n",
      "Iteration #705000: loss=0.020281720906496048\n",
      "Iteration #706000: loss=0.02028166688978672\n",
      "Iteration #707000: loss=0.020281614735722542\n",
      "Iteration #708000: loss=0.020281562581658363\n",
      "Iteration #709000: loss=0.020281510427594185\n",
      "Iteration #710000: loss=0.020281458273530006\n",
      "Iteration #711000: loss=0.020281406119465828\n",
      "Iteration #712000: loss=0.02028135396540165\n",
      "Iteration #713000: loss=0.02028130181133747\n",
      "Iteration #714000: loss=0.020281249657273293\n",
      "Iteration #715000: loss=0.020281197503209114\n",
      "Iteration #716000: loss=0.020281147211790085\n",
      "Iteration #717000: loss=0.020281095057725906\n",
      "Iteration #718000: loss=0.020281042903661728\n",
      "Iteration #719000: loss=0.02028099074959755\n",
      "Iteration #720000: loss=0.02028093859553337\n",
      "Iteration #721000: loss=0.02028089016675949\n",
      "Iteration #722000: loss=0.020280838012695312\n",
      "Iteration #723000: loss=0.020280785858631134\n",
      "Iteration #724000: loss=0.020280733704566956\n",
      "Iteration #725000: loss=0.020280683413147926\n",
      "Iteration #726000: loss=0.020280634984374046\n",
      "Iteration #727000: loss=0.020280582830309868\n",
      "Iteration #728000: loss=0.02028053253889084\n",
      "Iteration #729000: loss=0.02028048224747181\n",
      "Iteration #730000: loss=0.02028043009340763\n",
      "Iteration #731000: loss=0.0202803798019886\n",
      "Iteration #732000: loss=0.020280329510569572\n",
      "Iteration #733000: loss=0.020280277356505394\n",
      "Iteration #734000: loss=0.020280227065086365\n",
      "Iteration #735000: loss=0.020280178636312485\n",
      "Iteration #736000: loss=0.020280130207538605\n",
      "Iteration #737000: loss=0.020280078053474426\n",
      "Iteration #738000: loss=0.020280029624700546\n",
      "Iteration #739000: loss=0.020279977470636368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #740000: loss=0.02027992717921734\n",
      "Iteration #741000: loss=0.02027987875044346\n",
      "Iteration #742000: loss=0.02027983032166958\n",
      "Iteration #743000: loss=0.02027978003025055\n",
      "Iteration #744000: loss=0.02027972973883152\n",
      "Iteration #745000: loss=0.02027968131005764\n",
      "Iteration #746000: loss=0.02027963288128376\n",
      "Iteration #747000: loss=0.02027958258986473\n",
      "Iteration #748000: loss=0.0202795322984457\n",
      "Iteration #749000: loss=0.020279482007026672\n",
      "Iteration #750000: loss=0.020279433578252792\n",
      "Iteration #751000: loss=0.02027938701212406\n",
      "Iteration #752000: loss=0.020279336720705032\n",
      "Iteration #753000: loss=0.020279286429286003\n",
      "Iteration #754000: loss=0.020279238000512123\n",
      "Iteration #755000: loss=0.020279189571738243\n",
      "Iteration #756000: loss=0.020279141142964363\n",
      "Iteration #757000: loss=0.020279092714190483\n",
      "Iteration #758000: loss=0.020279042422771454\n",
      "Iteration #759000: loss=0.020278995856642723\n",
      "Iteration #760000: loss=0.020278947427868843\n",
      "Iteration #761000: loss=0.020278897136449814\n",
      "Iteration #762000: loss=0.020278850570321083\n",
      "Iteration #763000: loss=0.020278802141547203\n",
      "Iteration #764000: loss=0.020278755575418472\n",
      "Iteration #765000: loss=0.020278707146644592\n",
      "Iteration #766000: loss=0.020278658717870712\n",
      "Iteration #767000: loss=0.020278608426451683\n",
      "Iteration #768000: loss=0.020278559997677803\n",
      "Iteration #769000: loss=0.020278513431549072\n",
      "Iteration #770000: loss=0.02027846686542034\n",
      "Iteration #771000: loss=0.02027841843664646\n",
      "Iteration #772000: loss=0.02027837187051773\n",
      "Iteration #773000: loss=0.0202783215790987\n",
      "Iteration #774000: loss=0.02027827501296997\n",
      "Iteration #775000: loss=0.02027823030948639\n",
      "Iteration #776000: loss=0.02027818188071251\n",
      "Iteration #777000: loss=0.02027813531458378\n",
      "Iteration #778000: loss=0.0202780868858099\n",
      "Iteration #779000: loss=0.02027803845703602\n",
      "Iteration #780000: loss=0.020277991890907288\n",
      "Iteration #781000: loss=0.020277943462133408\n",
      "Iteration #782000: loss=0.020277896896004677\n",
      "Iteration #783000: loss=0.020277852192521095\n",
      "Iteration #784000: loss=0.020277803763747215\n",
      "Iteration #785000: loss=0.020277757197618484\n",
      "Iteration #786000: loss=0.020277710631489754\n",
      "Iteration #787000: loss=0.020277665928006172\n",
      "Iteration #788000: loss=0.020277617499232292\n",
      "Iteration #789000: loss=0.020277569070458412\n",
      "Iteration #790000: loss=0.02027752436697483\n",
      "Iteration #791000: loss=0.0202774778008461\n",
      "Iteration #792000: loss=0.02027743123471737\n",
      "Iteration #793000: loss=0.02027738466858864\n",
      "Iteration #794000: loss=0.020277339965105057\n",
      "Iteration #795000: loss=0.020277291536331177\n",
      "Iteration #796000: loss=0.020277244970202446\n",
      "Iteration #797000: loss=0.020277200266718864\n",
      "Iteration #798000: loss=0.020277153700590134\n",
      "Iteration #799000: loss=0.020277108997106552\n",
      "Iteration #800000: loss=0.02027706243097782\n",
      "Iteration #801000: loss=0.02027701772749424\n",
      "Iteration #802000: loss=0.02027697116136551\n",
      "Iteration #803000: loss=0.020276926457881927\n",
      "Iteration #804000: loss=0.020276879891753197\n",
      "Iteration #805000: loss=0.020276835188269615\n",
      "Iteration #806000: loss=0.020276788622140884\n",
      "Iteration #807000: loss=0.020276743918657303\n",
      "Iteration #808000: loss=0.02027669921517372\n",
      "Iteration #809000: loss=0.02027665264904499\n",
      "Iteration #810000: loss=0.02027660794556141\n",
      "Iteration #811000: loss=0.020276565104722977\n",
      "Iteration #812000: loss=0.020276520401239395\n",
      "Iteration #813000: loss=0.020276473835110664\n",
      "Iteration #814000: loss=0.020276429131627083\n",
      "Iteration #815000: loss=0.0202763844281435\n",
      "Iteration #816000: loss=0.02027633972465992\n",
      "Iteration #817000: loss=0.020276295021176338\n",
      "Iteration #818000: loss=0.020276248455047607\n",
      "Iteration #819000: loss=0.020276207476854324\n",
      "Iteration #820000: loss=0.020276160910725594\n",
      "Iteration #821000: loss=0.02027611806988716\n",
      "Iteration #822000: loss=0.02027607150375843\n",
      "Iteration #823000: loss=0.020276028662919998\n",
      "Iteration #824000: loss=0.020275985822081566\n",
      "Iteration #825000: loss=0.020275939255952835\n",
      "Iteration #826000: loss=0.020275896415114403\n",
      "Iteration #827000: loss=0.02027585171163082\n",
      "Iteration #828000: loss=0.02027580887079239\n",
      "Iteration #829000: loss=0.020275766029953957\n",
      "Iteration #830000: loss=0.020275721326470375\n",
      "Iteration #831000: loss=0.020275678485631943\n",
      "Iteration #832000: loss=0.02027563564479351\n",
      "Iteration #833000: loss=0.02027559094130993\n",
      "Iteration #834000: loss=0.020275548100471497\n",
      "Iteration #835000: loss=0.020275505259633064\n",
      "Iteration #836000: loss=0.020275460556149483\n",
      "Iteration #837000: loss=0.02027541771531105\n",
      "Iteration #838000: loss=0.020275374874472618\n",
      "Iteration #839000: loss=0.020275332033634186\n",
      "Iteration #840000: loss=0.020275289192795753\n",
      "Iteration #841000: loss=0.02027524821460247\n",
      "Iteration #842000: loss=0.020275205373764038\n",
      "Iteration #843000: loss=0.020275160670280457\n",
      "Iteration #844000: loss=0.020275117829442024\n",
      "Iteration #845000: loss=0.02027507685124874\n",
      "Iteration #846000: loss=0.02027503214776516\n",
      "Iteration #847000: loss=0.020274991169571877\n",
      "Iteration #848000: loss=0.020274948328733444\n",
      "Iteration #849000: loss=0.02027490735054016\n",
      "Iteration #850000: loss=0.020274866372346878\n",
      "Iteration #851000: loss=0.020274823531508446\n",
      "Iteration #852000: loss=0.020274780690670013\n",
      "Iteration #853000: loss=0.02027473971247673\n",
      "Iteration #854000: loss=0.020274696871638298\n",
      "Iteration #855000: loss=0.020274655893445015\n",
      "Iteration #856000: loss=0.020274613052606583\n",
      "Iteration #857000: loss=0.02027457393705845\n",
      "Iteration #858000: loss=0.020274532958865166\n",
      "Iteration #859000: loss=0.020274491980671883\n",
      "Iteration #860000: loss=0.0202744472771883\n",
      "Iteration #861000: loss=0.020274406298995018\n",
      "Iteration #862000: loss=0.020274367183446884\n",
      "Iteration #863000: loss=0.020274324342608452\n",
      "Iteration #864000: loss=0.020274285227060318\n",
      "Iteration #865000: loss=0.020274244248867035\n",
      "Iteration #866000: loss=0.020274203270673752\n",
      "Iteration #867000: loss=0.02027416042983532\n",
      "Iteration #868000: loss=0.020274121314287186\n",
      "Iteration #869000: loss=0.020274080336093903\n",
      "Iteration #870000: loss=0.02027403935790062\n",
      "Iteration #871000: loss=0.020274000242352486\n",
      "Iteration #872000: loss=0.020273959264159203\n",
      "Iteration #873000: loss=0.02027391828596592\n",
      "Iteration #874000: loss=0.020273879170417786\n",
      "Iteration #875000: loss=0.020273838192224503\n",
      "Iteration #876000: loss=0.020273800939321518\n",
      "Iteration #877000: loss=0.020273759961128235\n",
      "Iteration #878000: loss=0.020273717120289803\n",
      "Iteration #879000: loss=0.02027367800474167\n",
      "Iteration #880000: loss=0.020273638889193535\n",
      "Iteration #881000: loss=0.020273597911000252\n",
      "Iteration #882000: loss=0.020273560658097267\n",
      "Iteration #883000: loss=0.020273521542549133\n",
      "Iteration #884000: loss=0.02027348056435585\n",
      "Iteration #885000: loss=0.020273441448807716\n",
      "Iteration #886000: loss=0.020273402333259583\n",
      "Iteration #887000: loss=0.0202733613550663\n",
      "Iteration #888000: loss=0.020273324102163315\n",
      "Iteration #889000: loss=0.02027328498661518\n",
      "Iteration #890000: loss=0.020273244008421898\n",
      "Iteration #891000: loss=0.020273206755518913\n",
      "Iteration #892000: loss=0.02027316763997078\n",
      "Iteration #893000: loss=0.020273130387067795\n",
      "Iteration #894000: loss=0.02027309127151966\n",
      "Iteration #895000: loss=0.020273052155971527\n",
      "Iteration #896000: loss=0.020273013040423393\n",
      "Iteration #897000: loss=0.02027297392487526\n",
      "Iteration #898000: loss=0.020272934809327126\n",
      "Iteration #899000: loss=0.02027289755642414\n",
      "Iteration #900000: loss=0.020272856578230858\n",
      "Iteration #901000: loss=0.020272819325327873\n",
      "Iteration #902000: loss=0.02027278020977974\n",
      "Iteration #903000: loss=0.020272744819521904\n",
      "Iteration #904000: loss=0.02027270570397377\n",
      "Iteration #905000: loss=0.020272668451070786\n",
      "Iteration #906000: loss=0.02027262933552265\n",
      "Iteration #907000: loss=0.020272592082619667\n",
      "Iteration #908000: loss=0.020272552967071533\n",
      "Iteration #909000: loss=0.0202725138515234\n",
      "Iteration #910000: loss=0.020272478461265564\n",
      "Iteration #911000: loss=0.02027243934571743\n",
      "Iteration #912000: loss=0.020272400230169296\n",
      "Iteration #913000: loss=0.02027236297726631\n",
      "Iteration #914000: loss=0.020272327587008476\n",
      "Iteration #915000: loss=0.020272288471460342\n",
      "Iteration #916000: loss=0.020272251218557358\n",
      "Iteration #917000: loss=0.020272212103009224\n",
      "Iteration #918000: loss=0.02027217485010624\n",
      "Iteration #919000: loss=0.020272137597203255\n",
      "Iteration #920000: loss=0.02027210034430027\n",
      "Iteration #921000: loss=0.020272061228752136\n",
      "Iteration #922000: loss=0.02027202397584915\n",
      "Iteration #923000: loss=0.020271986722946167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #924000: loss=0.02027195133268833\n",
      "Iteration #925000: loss=0.020271914079785347\n",
      "Iteration #926000: loss=0.02027187868952751\n",
      "Iteration #927000: loss=0.020271839573979378\n",
      "Iteration #928000: loss=0.020271802321076393\n",
      "Iteration #929000: loss=0.02027176506817341\n",
      "Iteration #930000: loss=0.020271729677915573\n",
      "Iteration #931000: loss=0.02027169242501259\n",
      "Iteration #932000: loss=0.020271655172109604\n",
      "Iteration #933000: loss=0.02027161791920662\n",
      "Iteration #934000: loss=0.020271578803658485\n",
      "Iteration #935000: loss=0.02027154341340065\n",
      "Iteration #936000: loss=0.020271509885787964\n",
      "Iteration #937000: loss=0.02027147077023983\n",
      "Iteration #938000: loss=0.020271433517336845\n",
      "Iteration #939000: loss=0.02027139626443386\n",
      "Iteration #940000: loss=0.020271360874176025\n",
      "Iteration #941000: loss=0.02027132548391819\n",
      "Iteration #942000: loss=0.020271288231015205\n",
      "Iteration #943000: loss=0.02027125097811222\n",
      "Iteration #944000: loss=0.020271213725209236\n",
      "Iteration #945000: loss=0.0202711783349514\n",
      "Iteration #946000: loss=0.020271142944693565\n",
      "Iteration #947000: loss=0.02027110569179058\n",
      "Iteration #948000: loss=0.020271070301532745\n",
      "Iteration #949000: loss=0.02027103118598461\n",
      "Iteration #950000: loss=0.020270995795726776\n",
      "Iteration #951000: loss=0.02027096226811409\n",
      "Iteration #952000: loss=0.020270925015211105\n",
      "Iteration #953000: loss=0.02027088776230812\n",
      "Iteration #954000: loss=0.020270852372050285\n",
      "Iteration #955000: loss=0.0202708151191473\n",
      "Iteration #956000: loss=0.020270779728889465\n",
      "Iteration #957000: loss=0.02027074433863163\n",
      "Iteration #958000: loss=0.020270707085728645\n",
      "Iteration #959000: loss=0.02027067169547081\n",
      "Iteration #960000: loss=0.020270636305212975\n",
      "Iteration #961000: loss=0.02027060091495514\n",
      "Iteration #962000: loss=0.020270561799407005\n",
      "Iteration #963000: loss=0.02027052827179432\n",
      "Iteration #964000: loss=0.020270492881536484\n",
      "Iteration #965000: loss=0.02027045749127865\n",
      "Iteration #966000: loss=0.020270420238375664\n",
      "Iteration #967000: loss=0.02027038484811783\n",
      "Iteration #968000: loss=0.020270349457859993\n",
      "Iteration #969000: loss=0.020270314067602158\n",
      "Iteration #970000: loss=0.020270278677344322\n",
      "Iteration #971000: loss=0.020270241424441338\n",
      "Iteration #972000: loss=0.0202702097594738\n",
      "Iteration #973000: loss=0.020270170643925667\n",
      "Iteration #974000: loss=0.02027013525366783\n",
      "Iteration #975000: loss=0.020270101726055145\n",
      "Iteration #976000: loss=0.02027006633579731\n",
      "Iteration #977000: loss=0.020270030945539474\n",
      "Iteration #978000: loss=0.02026999369263649\n",
      "Iteration #979000: loss=0.020269962027668953\n",
      "Iteration #980000: loss=0.02026992477476597\n",
      "Iteration #981000: loss=0.020269887521862984\n",
      "Iteration #982000: loss=0.020269853994250298\n",
      "Iteration #983000: loss=0.020269818603992462\n",
      "Iteration #984000: loss=0.020269783213734627\n",
      "Iteration #985000: loss=0.02026974968612194\n",
      "Iteration #986000: loss=0.020269714295864105\n",
      "Iteration #987000: loss=0.02026967890560627\n",
      "Iteration #988000: loss=0.020269641652703285\n",
      "Iteration #989000: loss=0.02026960998773575\n",
      "Iteration #990000: loss=0.020269572734832764\n",
      "Iteration #991000: loss=0.02026953734457493\n",
      "Iteration #992000: loss=0.020269503816962242\n",
      "Iteration #993000: loss=0.020269466564059258\n",
      "Iteration #994000: loss=0.02026943303644657\n",
      "Iteration #995000: loss=0.020269395783543587\n",
      "Iteration #996000: loss=0.02026936411857605\n",
      "Iteration #997000: loss=0.020269326865673065\n",
      "Iteration #998000: loss=0.020269295200705528\n",
      "Iteration #999000: loss=0.020269257947802544\n",
      "Iteration #1000000: loss=0.020269222557544708\n"
     ]
    }
   ],
   "source": [
    "model = ConvDenseNNModel()\n",
    "cost_fn = torch.nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_stats = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    Y_pred = model(X).cuda()\n",
    "    loss = cost_fn(Y_pred, Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(\"Iteration #{}: loss={}\".format(i + 1, loss.item()))\n",
    "        loss_stats.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed757f3890>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_stats[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
