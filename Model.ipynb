{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BengaliAI CV 19 - Model & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # to make the results reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.0.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring GPU device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.0\"):\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    for gpu in gpus:\n",
    "        print(\"Configuring GPU device: {}\".format(str(gpu)))\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpu,\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7*1024)]\n",
    "        )\n",
    "else:\n",
    "    tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "    tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 train data file(s) found.\n"
     ]
    }
   ],
   "source": [
    "# Detect the number of train data mini batches. Shuffle them and divide into a train/test parts.\n",
    "\n",
    "fname_pattern = \"./bengaliai-cv19/train_batch_{:03d}.pickle\"\n",
    "train_test_split = 0.7\n",
    "\n",
    "mbatch_no = 0\n",
    "while os.path.exists(fname_pattern.format(mbatch_no)):\n",
    "    mbatch_no = mbatch_no + 1\n",
    "print(\"{} train data file(s) found.\".format(mbatch_no))\n",
    "\n",
    "mbatch_train_no = round(mbatch_no * 0.7)\n",
    "mbatch_test_no = mbatch_no - mbatch_train_no\n",
    "mbatch_idx = np.random.permutation(mbatch_no)\n",
    "mbatch_train_idx = mbatch_idx[:mbatch_train_no]\n",
    "mbatch_test_idx = mbatch_idx[mbatch_train_no:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional-Dense Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 137, 236)]        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 137, 236, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 133, 232, 256)     6656      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 133, 232, 256)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 67, 116, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 65, 114, 32)       73760     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 65, 114, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 33, 57, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 31, 55, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 31, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 13, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2912)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               1456500   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32332)             64696332  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 137, 236)          0         \n",
      "=================================================================\n",
      "Total params: 67,253,744\n",
      "Trainable params: 67,253,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Keras model\n",
    "X = tf.keras.layers.Input(shape=[137,236])\n",
    "A0 = tf.keras.layers.Reshape(target_shape=[137,236,1])(X)\n",
    "O0 = A0\n",
    "\n",
    "I1 = O0\n",
    "Z1 = tf.keras.layers.Conv2D(filters=256, kernel_size=[5,5], strides=[1,1], padding=\"valid\", dilation_rate=[1,1])(I1)\n",
    "A1 = tf.keras.layers.LeakyReLU(alpha=0.1)(Z1)\n",
    "P1 = tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=[2,2], padding=\"same\")(A1)\n",
    "O1 = P1\n",
    "\n",
    "I2 = O1\n",
    "Z2 = tf.keras.layers.Conv2D(filters=32, kernel_size=[3,3], strides=[1,1], padding=\"valid\", dilation_rate=[1,1])(I2)\n",
    "A2 = tf.keras.layers.LeakyReLU(alpha=0.1)(Z2)\n",
    "P2 = tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=[2,2], padding=\"same\")(A2)\n",
    "O2 = P2\n",
    "\n",
    "I3 = O2\n",
    "Z3 = tf.keras.layers.Conv2D(filters=32, kernel_size=[3,3], strides=[1,1], padding=\"valid\", dilation_rate=[1,1])(I3)\n",
    "A3 = tf.keras.layers.LeakyReLU(alpha=0.1)(Z3)\n",
    "P3 = tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=[2,2], padding=\"same\")(A3)\n",
    "O3 = P3\n",
    "\n",
    "I4 = O3\n",
    "Z4 = tf.keras.layers.Conv2D(filters=32, kernel_size=[3,3], strides=[1,1], padding=\"valid\", dilation_rate=[1,1])(I4)\n",
    "A4 = tf.keras.layers.LeakyReLU(alpha=0.1)(Z4)\n",
    "P4 = tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=[2,2], padding=\"same\")(A4)\n",
    "F4 = tf.keras.layers.Flatten()(P4)\n",
    "O4 = F4\n",
    "\n",
    "# <-- encoded here\n",
    "\n",
    "I5 = O4\n",
    "Z5 = tf.keras.layers.Dense(units=500, use_bias=True)(I5)\n",
    "A5 = tf.keras.layers.LeakyReLU(alpha=0.1)(Z5)\n",
    "O5 = A5\n",
    "\n",
    "I6 = O5\n",
    "Z6 = tf.keras.layers.Dense(units=2000, use_bias=True)(I6)\n",
    "A6 = tf.keras.layers.LeakyReLU(alpha=0.1)(Z6)\n",
    "O6 = A6\n",
    "\n",
    "I7 = O6\n",
    "Z7 = tf.keras.layers.Dense(units=236*137, use_bias=True)(I7)\n",
    "R7 = tf.keras.layers.Reshape(target_shape=[137,236])(Z7)\n",
    "O7 = R7\n",
    "\n",
    "Y = O7\n",
    "\n",
    "if tf.__version__.startswith(\"2.0\"):\n",
    "    model = tf.keras.models.Model(X, Y)\n",
    "else:\n",
    "    model = tf.keras.models.Model(inputs=X, outputs=Y)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
